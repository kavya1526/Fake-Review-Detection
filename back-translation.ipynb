{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T23:26:55.194817Z","iopub.execute_input":"2024-04-17T23:26:55.195214Z","iopub.status.idle":"2024-04-17T23:26:55.996815Z","shell.execute_reply.started":"2024-04-17T23:26:55.195183Z","shell.execute_reply":"2024-04-17T23:26:55.995778Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/yelp-fake-reviews/yelp_fake_reviews.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers==4.1.1 sentencepiece==0.1.94\n!pip install mosestokenizer==1.1.0","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:27:40.254335Z","iopub.execute_input":"2024-04-17T23:27:40.254846Z","iopub.status.idle":"2024-04-17T23:29:16.636576Z","shell.execute_reply.started":"2024-04-17T23:27:40.254815Z","shell.execute_reply":"2024-04-17T23:29:16.635225Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting transformers==4.1.1\n  Downloading transformers-4.1.1-py3-none-any.whl.metadata (34 kB)\nCollecting sentencepiece==0.1.94\n  Downloading sentencepiece-0.1.94.tar.gz (507 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.5/507.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (3.13.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (2.31.0)\nCollecting sacremoses (from transformers==4.1.1)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nCollecting tokenizers==0.9.4 (from transformers==4.1.1)\n  Downloading tokenizers-0.9.4.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.1.1) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->transformers==4.1.1) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.1.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.1.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.1.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.1.1) (2024.2.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.1.1) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.1.1) (1.3.2)\nDownloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentencepiece, tokenizers\n  Building wheel for sentencepiece (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentencepiece: filename=sentencepiece-0.1.94-cp310-cp310-linux_x86_64.whl size=1151521 sha256=12d2d218a4affc77ea415f8b5a8fe13aa92a0e3d208deec0895c4471ccd7d0f3\n  Stored in directory: /root/.cache/pip/wheels/09/a1/54/a3196ca6f241737de6ae3dcdf00a80383f9dd5e5f7dc78a97e\n  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[47 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m running bdist_wheel\n  \u001b[31m   \u001b[0m running build\n  \u001b[31m   \u001b[0m running build_py\n  \u001b[31m   \u001b[0m creating build\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m running build_ext\n  \u001b[31m   \u001b[0m running build_rust\n  \u001b[31m   \u001b[0m error: can't find Rust compiler\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m To update pip, run:\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m     pip install --upgrade pip\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m and then retry package installation.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25hSuccessfully built sentencepiece\nFailed to build tokenizers\n\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n\u001b[0mCollecting mosestokenizer==1.1.0\n  Downloading mosestokenizer-1.1.0.tar.gz (37 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from mosestokenizer==1.1.0) (0.6.2)\nCollecting openfile (from mosestokenizer==1.1.0)\n  Downloading openfile-0.0.7-py3-none-any.whl.metadata (1.7 kB)\nCollecting uctools (from mosestokenizer==1.1.0)\n  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting toolwrapper (from mosestokenizer==1.1.0)\n  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hDownloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\nBuilding wheels for collected packages: mosestokenizer, toolwrapper, uctools\n  Building wheel for mosestokenizer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mosestokenizer: filename=mosestokenizer-1.1.0-py3-none-any.whl size=49101 sha256=8c9cd80749e4bdb611faf825790f1ca5d0eab6b483bf8579390b56933d1f5809\n  Stored in directory: /root/.cache/pip/wheels/c4/88/71/f9d275d1de697768e53fdb0045dc9adc5b0e067a078fb51c46\n  Building wheel for toolwrapper (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3338 sha256=765dcec5cf9f5845425d63987bba8940089a6505e7a32622b4c4b04da5289dc7\n  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n  Building wheel for uctools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=e3cfea5a5c8c257cf17d61266104fe70715300dd10d07f84a9bb1b8a11003f05\n  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\nSuccessfully built mosestokenizer toolwrapper uctools\nInstalling collected packages: toolwrapper, openfile, uctools, mosestokenizer\nSuccessfully installed mosestokenizer-1.1.0 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nimport numpy as np\nfrom tqdm import tqdm\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom collections import defaultdict\n\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:16.639066Z","iopub.execute_input":"2024-04-17T23:29:16.639432Z","iopub.status.idle":"2024-04-17T23:29:23.684786Z","shell.execute_reply.started":"2024-04-17T23:29:16.639390Z","shell.execute_reply":"2024-04-17T23:29:23.683868Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/yelp-fake-reviews/yelp_fake_reviews.csv\", encoding=\"latin1\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:26.722883Z","iopub.execute_input":"2024-04-17T23:29:26.723449Z","iopub.status.idle":"2024-04-17T23:29:27.116162Z","shell.execute_reply.started":"2024-04-17T23:29:26.723417Z","shell.execute_reply":"2024-04-17T23:29:27.115146Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def map_labels(label):\n    if label == 1:\n        return 1\n    elif label == -1:\n        return 0\n    else:\n        return label\ndf['LABEL'] = df['LABEL'].apply(map_labels)\n#Drop columns which are not necessary\ndf.drop([\"RATING_DEVIATION\",\"RATING_CATEGORY\",\n         \"SINGLE_RATING_CATEGORY\",\"REVIEW_COUNT_DATE\",\n         \"MAX_USER_REVIEWS_DAY\",\n         \"RATIO_POSITIVE_NEGATIVE\", \"Unnamed: 0\", \"PERCENTAGE_POSITIVE_REVIEWS\"], axis=1, inplace=True)\ndf.LABEL.apply(map_labels)\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:28.159061Z","iopub.execute_input":"2024-04-17T23:29:28.159454Z","iopub.status.idle":"2024-04-17T23:29:28.213839Z","shell.execute_reply.started":"2024-04-17T23:29:28.159423Z","shell.execute_reply":"2024-04-17T23:29:28.212869Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['USER_ID', 'PRODUCT_ID', 'RATING', 'DATE', 'LABEL', 'REVIEW_TEXT',\n       'AVERAGE_RATING', 'TOTAL_PRODUCT_REVIEWS', 'REVIEW_LENGTH',\n       'SAME_DATE_MULTIPLE_REVIEWS', 'TIMESTAMP_DIFFERENCE',\n       'AVERAGE_USER_REVIEW_LENGTH', 'TOTAL_USER_REVIEWS'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"def data_clean(data):\n    # total rows in data\n    print(\"Total no. of rows in data:\", len(data))\n\n    # checking numbers of NaNs in all columns\n    print(\"Total no. of NaNs in 'RATING' column:\", data['RATING'].isnull().sum())\n    print(\"Total no. of NaNs in 'LABEL' column:\", data['LABEL'].isnull().sum())\n    print(\"Total no. of NaNs in 'REVIEW_TEXT' column:\", data['REVIEW_TEXT'].isnull().sum())\n\n    # removing the rows containing NaNs in 'category' column\n    # data = data[data['LABEL'].notna()]\n    # print(\"Total no. of rows in data after removing NaNs:\", len(data))\n\n    # count of CG and OR reviews\n    print(\"Count of CG and OR reviews:\", data['LABEL'].value_counts())\n    print(\"Ratio of CG and OR REVIEWS:\", data['LABEL'].value_counts(normalize=True))\n\n    # avg number of words in review of CG and OR reviews\n    data['word_count'] = data['REVIEW_TEXT'].str.split().str.len()\n    print(\"Average count of words in CG and OR reviews:\", data.groupby('LABEL')['word_count'].mean())\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:28.979361Z","iopub.execute_input":"2024-04-17T23:29:28.979786Z","iopub.status.idle":"2024-04-17T23:29:28.988798Z","shell.execute_reply.started":"2024-04-17T23:29:28.979754Z","shell.execute_reply":"2024-04-17T23:29:28.987467Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = data_clean(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:30.431063Z","iopub.execute_input":"2024-04-17T23:29:30.431431Z","iopub.status.idle":"2024-04-17T23:29:30.825445Z","shell.execute_reply.started":"2024-04-17T23:29:30.431404Z","shell.execute_reply":"2024-04-17T23:29:30.824221Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total no. of rows in data: 20000\nTotal no. of NaNs in 'RATING' column: 0\nTotal no. of NaNs in 'LABEL' column: 0\nTotal no. of NaNs in 'REVIEW_TEXT' column: 0\nCount of CG and OR reviews: LABEL\n1    17926\n0     2074\nName: count, dtype: int64\nRatio of CG and OR REVIEWS: LABEL\n1    0.8963\n0    0.1037\nName: proportion, dtype: float64\nAverage count of words in CG and OR reviews: LABEL\n0     83.632112\n1    121.903269\nName: word_count, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"data_OR = data.loc[data['LABEL'] == 1]\ndata_OR_series = data_OR['REVIEW_TEXT'].to_list()[:6000]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:42.515565Z","iopub.execute_input":"2024-04-17T23:29:42.516397Z","iopub.status.idle":"2024-04-17T23:29:42.527310Z","shell.execute_reply.started":"2024-04-17T23:29:42.516364Z","shell.execute_reply":"2024-04-17T23:29:42.526142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"len(data_OR_series)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:43.228467Z","iopub.execute_input":"2024-04-17T23:29:43.228905Z","iopub.status.idle":"2024-04-17T23:29:43.235948Z","shell.execute_reply.started":"2024-04-17T23:29:43.228873Z","shell.execute_reply":"2024-04-17T23:29:43.234822Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"6000"},"metadata":{}}]},{"cell_type":"code","source":"# functions for back translation (Reference - https://amitness.com/back-translation/)\ntarget_model_name = 'Helsinki-NLP/opus-mt-en-fr'\ntarget_tokenizer = MarianTokenizer.from_pretrained(target_model_name)\ntarget_model = MarianMTModel.from_pretrained(target_model_name).to('cuda:0')\n\nen_model_name = 'Helsinki-NLP/opus-mt-fr-en'\nen_tokenizer = MarianTokenizer.from_pretrained(en_model_name)\nen_model = MarianMTModel.from_pretrained(en_model_name).to('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:44.915120Z","iopub.execute_input":"2024-04-17T23:29:44.915808Z","iopub.status.idle":"2024-04-17T23:29:58.387684Z","shell.execute_reply.started":"2024-04-17T23:29:44.915777Z","shell.execute_reply":"2024-04-17T23:29:58.386487Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e54191dbf44c96ad32d1115b997c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd51656c04aa4577885028ede785b713"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e73124909c4e7c8e218733bee64cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c56450f72525406f9cc2e942b4927453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81c3d36418a647ddb0b718534d35996a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d9ccbdde83a43d6bd807f825fad5bb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c22ea2da805d4112a589a6cb0bdecf39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d389bf12e542a0bbd2f44c7aa8706b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5befe3d599a2420083416ff7c6fd73df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"020fa8ef9a2545289e0d7ee6d023dea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f020d447769490cbf30aa8172500bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3692ca94b9744b35971ecfad3babc83f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3f6954449f64b0cae91eae3f9dafc16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11caf14919c4b00a7a5a1c3abb37fc6"}},"metadata":{}}]},{"cell_type":"code","source":"def translate(texts, model, tokenizer, language=\"fr\"):\n    # Prepare the text data into appropriate format for the model\n    template = lambda text: f\"{text}\" if language == \"en\" else f\">>{language}<< {text}\"\n    src_texts = [template(text) for text in texts]\n\n    # Tokenize the texts\n    encoded = tokenizer.prepare_seq2seq_batch(src_texts,return_tensors=\"pt\").to('cuda:0')\n\n    # Generate translation using model\n    translated = model.generate(**encoded)\n\n    # Convert the generated tokens indices back into text\n    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n\n    return translated_texts\n\ndef back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n    # Translate from source to target language\n    fr_texts = translate(texts, target_model, target_tokenizer,\n                         language=target_lang)\n\n    # Translate from target language back to source language\n    back_translated_texts = translate(fr_texts, en_model, en_tokenizer, language=source_lang)\n\n    return back_translated_texts","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:29:58.389635Z","iopub.execute_input":"2024-04-17T23:29:58.389999Z","iopub.status.idle":"2024-04-17T23:29:58.398572Z","shell.execute_reply.started":"2024-04-17T23:29:58.389963Z","shell.execute_reply":"2024-04-17T23:29:58.397483Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# breaking augmentation data into batches for easier processing\nbatch_size = 25 # should be a multiple of length of original data (6000)\nnum_batches = int(len(data_OR_series) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:30:03.461944Z","iopub.execute_input":"2024-04-17T23:30:03.462353Z","iopub.status.idle":"2024-04-17T23:30:03.467595Z","shell.execute_reply.started":"2024-04-17T23:30:03.462323Z","shell.execute_reply":"2024-04-17T23:30:03.466175Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# function which takes a list as input and returns a dictionary of lists containing the outputs of back translation\ndef back_translation_output(data):\n    i = 0\n    d_data = defaultdict(list)\n    d_data_out = defaultdict(list)\n    for i in tqdm(range(num_batches)):\n        d_data[i] = data[i*batch_size:(i+1)*batch_size]\n        d_data_out[i] = back_translate(d_data[i])\n\n    return d_data_out","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:30:12.955240Z","iopub.execute_input":"2024-04-17T23:30:12.955648Z","iopub.status.idle":"2024-04-17T23:30:12.961763Z","shell.execute_reply.started":"2024-04-17T23:30:12.955616Z","shell.execute_reply":"2024-04-17T23:30:12.960657Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_CG_bt = back_translation_output(data_OR_series)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T23:30:14.437894Z","iopub.execute_input":"2024-04-17T23:30:14.438310Z","iopub.status.idle":"2024-04-18T01:37:13.309878Z","shell.execute_reply.started":"2024-04-17T23:30:14.438279Z","shell.execute_reply":"2024-04-18T01:37:13.308820Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 240/240 [2:06:58<00:00, 31.75s/it]  \n","output_type":"stream"}]},{"cell_type":"code","source":"data_OR.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:39:52.612314Z","iopub.execute_input":"2024-04-18T01:39:52.613142Z","iopub.status.idle":"2024-04-18T01:39:52.635575Z","shell.execute_reply.started":"2024-04-18T01:39:52.613101Z","shell.execute_reply":"2024-04-18T01:39:52.634618Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   USER_ID  PRODUCT_ID  RATING        DATE  LABEL  \\\n1    74755         449       4  2013-03-26      1   \n2    49165         237       3  2011-10-11      1   \n3    75653         363       5  2014-01-14      1   \n4    32402         100       4  2014-12-02      1   \n5    14924          50       5  2014-10-12      1   \n\n                                         REVIEW_TEXT  AVERAGE_RATING  \\\n1  My family and I had Bubby's brunch on a Saturd...        3.396552   \n2  I really like this place, but they need to get...        3.799003   \n3  This is one of my favorite places in the US. A...        3.990361   \n4  Make sure you go with a small group of friends...        3.951812   \n5  Have been coming here since they opened. The q...        4.351714   \n\n   TOTAL_PRODUCT_REVIEWS  REVIEW_LENGTH  SAME_DATE_MULTIPLE_REVIEWS  \\\n1                    812            824                           0   \n2                    602            314                           0   \n3                   2075            280                           0   \n4                   2677            478                           0   \n5                    671            247                           0   \n\n  TIMESTAMP_DIFFERENCE  AVERAGE_USER_REVIEW_LENGTH  TOTAL_USER_REVIEWS  \\\n1            1723 days                  724.666667                  12   \n2               0 days                  314.000000                   1   \n3               0 days                  280.000000                   1   \n4             398 days                  255.666667                   3   \n5               0 days                  247.000000                   1   \n\n   word_count  \n1         156  \n2          50  \n3          50  \n4          93  \n5          43  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USER_ID</th>\n      <th>PRODUCT_ID</th>\n      <th>RATING</th>\n      <th>DATE</th>\n      <th>LABEL</th>\n      <th>REVIEW_TEXT</th>\n      <th>AVERAGE_RATING</th>\n      <th>TOTAL_PRODUCT_REVIEWS</th>\n      <th>REVIEW_LENGTH</th>\n      <th>SAME_DATE_MULTIPLE_REVIEWS</th>\n      <th>TIMESTAMP_DIFFERENCE</th>\n      <th>AVERAGE_USER_REVIEW_LENGTH</th>\n      <th>TOTAL_USER_REVIEWS</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>74755</td>\n      <td>449</td>\n      <td>4</td>\n      <td>2013-03-26</td>\n      <td>1</td>\n      <td>My family and I had Bubby's brunch on a Saturd...</td>\n      <td>3.396552</td>\n      <td>812</td>\n      <td>824</td>\n      <td>0</td>\n      <td>1723 days</td>\n      <td>724.666667</td>\n      <td>12</td>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49165</td>\n      <td>237</td>\n      <td>3</td>\n      <td>2011-10-11</td>\n      <td>1</td>\n      <td>I really like this place, but they need to get...</td>\n      <td>3.799003</td>\n      <td>602</td>\n      <td>314</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>314.000000</td>\n      <td>1</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75653</td>\n      <td>363</td>\n      <td>5</td>\n      <td>2014-01-14</td>\n      <td>1</td>\n      <td>This is one of my favorite places in the US. A...</td>\n      <td>3.990361</td>\n      <td>2075</td>\n      <td>280</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>280.000000</td>\n      <td>1</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32402</td>\n      <td>100</td>\n      <td>4</td>\n      <td>2014-12-02</td>\n      <td>1</td>\n      <td>Make sure you go with a small group of friends...</td>\n      <td>3.951812</td>\n      <td>2677</td>\n      <td>478</td>\n      <td>0</td>\n      <td>398 days</td>\n      <td>255.666667</td>\n      <td>3</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14924</td>\n      <td>50</td>\n      <td>5</td>\n      <td>2014-10-12</td>\n      <td>1</td>\n      <td>Have been coming here since they opened. The q...</td>\n      <td>4.351714</td>\n      <td>671</td>\n      <td>247</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>247.000000</td>\n      <td>1</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_CG = data_OR.drop(['LABEL', 'REVIEW_TEXT', 'word_count', 'REVIEW_LENGTH'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:41:03.284097Z","iopub.execute_input":"2024-04-18T01:41:03.284972Z","iopub.status.idle":"2024-04-18T01:41:03.292263Z","shell.execute_reply.started":"2024-04-18T01:41:03.284930Z","shell.execute_reply":"2024-04-18T01:41:03.290987Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_CG.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:41:14.047850Z","iopub.execute_input":"2024-04-18T01:41:14.048262Z","iopub.status.idle":"2024-04-18T01:41:14.065581Z","shell.execute_reply.started":"2024-04-18T01:41:14.048233Z","shell.execute_reply":"2024-04-18T01:41:14.064438Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   USER_ID  PRODUCT_ID  RATING        DATE  AVERAGE_RATING  \\\n1    74755         449       4  2013-03-26        3.396552   \n2    49165         237       3  2011-10-11        3.799003   \n3    75653         363       5  2014-01-14        3.990361   \n4    32402         100       4  2014-12-02        3.951812   \n5    14924          50       5  2014-10-12        4.351714   \n\n   TOTAL_PRODUCT_REVIEWS  SAME_DATE_MULTIPLE_REVIEWS TIMESTAMP_DIFFERENCE  \\\n1                    812                           0            1723 days   \n2                    602                           0               0 days   \n3                   2075                           0               0 days   \n4                   2677                           0             398 days   \n5                    671                           0               0 days   \n\n   AVERAGE_USER_REVIEW_LENGTH  TOTAL_USER_REVIEWS  \n1                  724.666667                  12  \n2                  314.000000                   1  \n3                  280.000000                   1  \n4                  255.666667                   3  \n5                  247.000000                   1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USER_ID</th>\n      <th>PRODUCT_ID</th>\n      <th>RATING</th>\n      <th>DATE</th>\n      <th>AVERAGE_RATING</th>\n      <th>TOTAL_PRODUCT_REVIEWS</th>\n      <th>SAME_DATE_MULTIPLE_REVIEWS</th>\n      <th>TIMESTAMP_DIFFERENCE</th>\n      <th>AVERAGE_USER_REVIEW_LENGTH</th>\n      <th>TOTAL_USER_REVIEWS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>74755</td>\n      <td>449</td>\n      <td>4</td>\n      <td>2013-03-26</td>\n      <td>3.396552</td>\n      <td>812</td>\n      <td>0</td>\n      <td>1723 days</td>\n      <td>724.666667</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49165</td>\n      <td>237</td>\n      <td>3</td>\n      <td>2011-10-11</td>\n      <td>3.799003</td>\n      <td>602</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>314.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75653</td>\n      <td>363</td>\n      <td>5</td>\n      <td>2014-01-14</td>\n      <td>3.990361</td>\n      <td>2075</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>280.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32402</td>\n      <td>100</td>\n      <td>4</td>\n      <td>2014-12-02</td>\n      <td>3.951812</td>\n      <td>2677</td>\n      <td>0</td>\n      <td>398 days</td>\n      <td>255.666667</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14924</td>\n      <td>50</td>\n      <td>5</td>\n      <td>2014-10-12</td>\n      <td>4.351714</td>\n      <td>671</td>\n      <td>0</td>\n      <td>0 days</td>\n      <td>247.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_CG['LABEL'] = 0","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:41:40.155944Z","iopub.execute_input":"2024-04-18T01:41:40.156770Z","iopub.status.idle":"2024-04-18T01:41:40.162238Z","shell.execute_reply.started":"2024-04-18T01:41:40.156736Z","shell.execute_reply":"2024-04-18T01:41:40.161180Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data_CG_bt_list = list(data_CG_bt.values())","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:41:55.137425Z","iopub.execute_input":"2024-04-18T01:41:55.138229Z","iopub.status.idle":"2024-04-18T01:41:55.142810Z","shell.execute_reply.started":"2024-04-18T01:41:55.138192Z","shell.execute_reply":"2024-04-18T01:41:55.141617Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"final_text_CG_list = []\nfor i in range(len(data_CG_bt_list)):\n    for j in range(len(data_CG_bt_list[i])):\n        final_text_CG_list.append(data_CG_bt_list[i][j])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:42:14.864093Z","iopub.execute_input":"2024-04-18T01:42:14.864884Z","iopub.status.idle":"2024-04-18T01:42:14.873180Z","shell.execute_reply.started":"2024-04-18T01:42:14.864851Z","shell.execute_reply":"2024-04-18T01:42:14.871937Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"with open('your_file.txt', 'w') as f:\n    for line in lines:\n        f.write(f\"{line}\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_CG['REVIEW_TEXT'] = final_text_CG_list","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:42:37.903963Z","iopub.execute_input":"2024-04-18T01:42:37.904657Z","iopub.status.idle":"2024-04-18T01:42:39.088377Z","shell.execute_reply.started":"2024-04-18T01:42:37.904623Z","shell.execute_reply":"2024-04-18T01:42:39.087005Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_CG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mREVIEW_TEXT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m final_text_CG_list\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4298\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4512\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4504\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4505\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4510\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4512\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4515\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4516\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4517\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4518\u001b[0m     ):\n\u001b[1;32m   4519\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4520\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5253\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5253\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5254\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5256\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5261\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Length of values (6000) does not match length of index (17926)"],"ename":"ValueError","evalue":"Length of values (6000) does not match length of index (17926)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}